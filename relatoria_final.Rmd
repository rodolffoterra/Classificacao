---
title: "<b>Prevenção de Ocorrência de Câncer de Mama</b>"
author: "Rodolfo R. Terra | Cientista de Dados"
output:
  html_document:
    df_print: paged
  pdf_document: default
  pdf_documentt: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<h1><b>Sumário</b></h1>
<p> <font color = white>...</font></p>


<p class="shytext"> 1.<a href="#1"><strong> Coletando os Dados</strong></a></p>

<p class="shytext"> 2.<a href="#2"><strong> Pré-Processamento</strong></a></p>

<p class="shytext"> 3.<a href="#3"><strong> Treinando o modelo com knn</strong></a></p>

<p class="shytext"> 3.1.<a href="#3.1"><strong> Avaliando o Modelo 1 - knn</strong></a></p>

<p class="shytext"> 3.2.<a href="#3.2"><strong> Interpretando os resultados do modelo 1 - knn</strong></a></p>

<p class="shytext"> 3.3.<a href="#3.3"><strong> Otimizando a Performance - Modelo 2 - knn</strong></a></p>

<p class="shytext"> 3.4.<a href="#3.4"><strong> Interpretando os resultados do modelo 2 - knn</strong></a></p>

<p class="shytext"> 4.<a href="#4"><strong> Construindo um Modelo com Algoritmo Support Vector Machine (Ssvm) - modelo 3</strong></a></p>

<p class="shytext"> 4.1.<a href="#4.1"><strong> Avaliando dos Modelo 3 (svm)</strong></a></p>

<p class="shytext"> 4.2.<a href="#4.2"><strong> Interpretando os resultados do o Modelo 3 (svm)</strong></a></p>

<p class="shytext"> 5.<a href="#5"><strong> Construindo o Modelo  4 - Random Forest</strong></a></p>

<p class="shytext"> 5.1.<a href="#5.1"><strong>Interpretando os resultados do o Modelo 4 (Random Forest)</strong></a></p>


<p class="shytext"> 6.<a href="#6"><strong> Conslusão</strong></a></p>


<h2><b>Definição do Problema de Negócio</h2></b>

<h5>Revisão de ocorrência de câncer de nama.</h5>
<b> Desenvolvimento de um modelo ML que que prever o tipo e câncer do paciente: Benigno ou maligno, analisando os exames médicos.</b> 
<h5>Para o desenvolvimento do modelo ML foi observado o conjunto de dados,com 569 pacientes com câncer, sendo de dois tipos: <b>Benigno</b> e <b>Maligno</b>, chamado de coluna target ou o que queremos prever e também os resultados de 31 tipos de exames, chamado de variáveis.</h5>


</h5>
<h5>O conjunto de dados foi pego no link abaixo, dados públicos para a utilização:</h5>
<p class="shytext">http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29<a href=http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29></a></p>

<a name="1"> </a>
<h3><b>Etapa 1 - Coletando os Dados</h3></b>

<h5>Aqui está a coleta de dados.</h5>


```{r coleta}
# Coletando dados
dados <- read.csv("dataset.csv", stringsAsFactors = FALSE)
str(dados)
head(dados)
tail(dados)
```

<a name="2"> </a>
<h3><b>Etapa 2 - Pré-Processamento</h3></b>

<h5>Excluindo a coluna ID</h5>
<h5>Independentemente do método de aprendizagem de máquina, deve sempre ser excluídas variáveis de <b>"ID"</B>. Caso contrário, isso pode levar a resultados errados porque o <b>ID</b> pode ser usado para unicamente <b>"prever"</b> cada exemplo. Por conseguinte, um modelo que inclui um  identificador pode sofrer de superajuste (overfitting), e será muito difícil usá-lo para generalizar outros dados.</h5>

```{r p.processamento}

dados$id <- NULL

# Ajustando o label da variável alvo
dados$diagnosis = sapply(dados$diagnosis, function(x){ifelse(x=="M", "Maligno", "Benigno")})

head(dados)

# Muitos classificadores requerem que as variáveis sejam do tipo Fator
table(dados$diagnosis)
dados$diagnosis <- factor(dados$diagnosis, levels = c('Benigno', "Maligno"), labels = c("Benigno", "Maligno"))
str(dados$diagnosis)

# Verificando a proporção
round(prop.table(table(dados$diagnosis))*100, digits = 1)

library(ggplot2)

ggplot(dados, aes(x=diagnosis)) + ggtitle('Tipos de Câncer: Benigno e Maligno') + xlab("Tipo de Cancer") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentual") + coord_flip() + theme_minimal()
```


<b>Medida de Tendência Central</b>

Ao detectar um problema de escala entre os dados, é preciso realizar a normalização do modelo, ou seja, deixar todas as variáveis numéricas em uma mesma escala.
O cálculo de distância feito pelo kNN é dependente das medidas de escala nos dados de entrada.

```{r summary}
summary(dados)
summary(dados[c("radius_mean", "area_mean", "smoothness_mean")])
````

<b>Criando uma Função de Normalização</b>

```{r normalizacao}
normalizar <- function(x){
  return ((x - min(x)) / (max(x) - min(x)))
}
```

<b>Normalizando os Dados<b>

```{r fomr2}
dados_norm <- as.data.frame(lapply(dados[2:31], normalizar))
head(dados_norm)
```


<a name="3"> </a>
<h3><b>Etapa 3 - Treinando o modelo com knn</h3></b>

```{r treino1}

library(class)
library(caTools)

# Criando dados de treino e dados de teste

dados_treino <- dados_norm[1:469, ]
dados_teste <- dados_norm[470:569, ]

# Criando os labels para os dados de treino e de teste
dados_treino_labels <- dados[1:469, 1]
dados_teste_labels <- dados[470:569, 1]
length(dados_treino_labels)
length(dados_teste_labels)

# Criando o modelo
modelo_knn_v1 <- knn(train = dados_treino, 
                     test = dados_teste,
                     cl = dados_treino_labels, 
                     k = 21)

# A função knn() retorna um objeto do tipo fator com as previsões para cada exemplo no dataset de teste

summary(modelo_knn_v1)

```

<a name="3.1"> </a>
<h3><b>Etapa 3.1 - Avaliando o Modelo 1 - knn</h3></b>


```{r mod1}
library(gmodels)

# Criando uma tabela cruzada dos dados previstos x dados atuais
# Usaremos amostra com 100 observações: length(dados_teste_labels)
CrossTable(x = dados_teste_labels, y = modelo_knn_v1, prop.chisq = FALSE)

```

<a name="3.2"> </a>
<h3><b>Etapa 3.2 - Interpretando os resultados do modelo 1 - knn</h3></b>

<h5> A tabela cruzada mostra 4 possíveis valores, que representam os falso/verdadeiro positivo e negativo.
Temos duas colunas listando os labels originais nos dados observados. Temos duas linhas listando os labels dos dados de teste

<b>Temos:</b>
<h5>* Cenário 1: Célula Benigno (Observado) x Benigno (Previsto) - 61 casos - true positive;
* Cenário 2: Célula Maligno (Observado) x Benigno (Previsto) - 00 casos - false positive (o modelo errou);
* Cenário 3: Célula Benigno (Observado) x Maligno (Previsto) - 02 casos - false negative (o modelo errou);
* Cenário 4: Célula Maligno (Observado) x Maligno (Previsto) - 37 casos - true negative;</h5> 

<b>Lendo a Confusion Matrix (Perspectiva de ter ou não a doença):</b>

<h5>* True Negative  = nosso modelo previu que a pessoa NÃO tinha a doença e os dados mostraram que realmente a pessoa NÃO tinha a doença;
* False Positive = nosso modelo previu que a pessoa tinha a doença e os dados mostraram que NÃO, a pessoa tinha a doença
+ False Negative = nosso modelo previu que a pessoa NÃO tinha a doença e os dados mostraram que SIM, a pessoa tinha a doença
* True Positive = nosso modelo previu que a pessoa tinha a doença e os dados mostraram que SIM, a pessoa tinha a doença</h5>

<h5>Falso Positivo - Erro Tipo I
Falso Negativo - Erro Tipo II</h5>

<b>Taxa de acerto do Modelo: 98% (acertou 98 em 100)</b>

<a name="3.3"> </a>
<h3><b>Etapa 3.3 - Otimizando a Performance - Modelo 2 - knn</h3></b>

<h5>Usando a função scale() para padronizar o z-score <h5>



```{r inter1}
dados_z <- as.data.frame(scale(dados[-1]))

# Confirmando transformação realizada com sucesso
summary(dados$area_mean)

# Criando novos datasets de treino e de teste

dados_treino1 <- dados_z[1:469, ]
dados_teste1 <- dados_z[470:569, ]

dados_treino1_labels <- dados[1:469, 1]
dados_teste1_labels <- dados[470:569, 1]

modelo_knn_v2 <- knn(train = dados_treino1,
                     test = dados_teste1,
                     cl = dados_treino1_labels,
                     k = 21)

# Criando uma tabela cruzada dos dados previstos x dados atuais

CrossTable(x = dados_teste1_labels, modelo_knn_v2, prop.chisq = FALSE)

```

<a name="3.4"> </a>
<h3><b>Etapa 3.4 - Interpretando os resultados do modelo 2 - knn</h3></b>

<b>Temos:</b>
<h5>* Cenário 1: Célula Benigno (Observado) x Benigno (Previsto) - 61 casos - true positive;
* Cenário 2: Célula Maligno (Observado) x Benigno (Previsto) - 00 casos - false positive (o modelo errou);
* Cenário 3: Célula Benigno (Observado) x Maligno (Previsto) - 05 casos - false negative (o modelo errou);
* Cenário 4: Célula Maligno (Observado) x Maligno (Previsto) - 34 casos - true negative;</h5> 
<h5>Podemos observar que aumentou a quantidade de erros em nosso modelo.</h5>
<b>Taxa de acerto do Modelo: 95%;</b>
<h5>Comparamos apenas o primeiro e o segundo modelo ficaremos por enquanto com o primeiro modelo.</h5>

<a name="4"> </a>
<h3><b>Etapa 4 - Construindo um Modelo com Algoritmo Support Vector Machine (svm) - modelo 3</h3></b>

``` {r mod3}

# Prepara o dataset

dados1 <- read.csv("dataset.csv", stringsAsFactors = FALSE)
dados1$id = NULL
dados1[,'index'] <- ifelse(runif(nrow(dados1)) < 0.8,1,0)
head(dados1)

# Dados de treino e teste
trainset <- dados1[dados1$index==1,]
testset <- dados1[dados1$index==0,]

# Obter o índice 
trainColNum <- grep('index', names(trainset))

# Remover o índice dos datasets
trainset <- trainset[,-trainColNum]
testset <- testset[,-trainColNum]

# Obter índice de coluna da variável target no conjunto de dados
typeColNum <- grep('diag',names(dados1))

# Cria o modelo
# Nós ajustamos o kernel para radial, já que este conjunto de dados não tem um 
# plano linear que pode ser desenhado
library(e1071)
set.seed(50) 

modelo_svm_v1 <- svm(diagnosis ~ ., 
                     data = trainset, 
                     type = 'C-classification', 
                     kernel = 'radial')

```


<a name="4.1"> </a>
<h3><b>Etapa 4.1 - Avaliando o Modelo 3 (svm)</h3></b>

```{r prev3}

# Previsões nos dados de treino
pred_train <- predict(modelo_svm_v1, trainset) 

# Percentual de previsões corretas com dataset de treino
acuracia_modelo3 <- mean(pred_train == trainset$diagnosis)  
acuracia_modelo3

# Previsões nos dados de teste
pred_test <- predict(modelo_svm_v1, testset) 

# Percentual de previsões corretas com dataset de teste
mean(pred_test == testset$diagnosis)  

# Confusion Matrix
table(pred_test, testset$diagnosis)
table(pred_train, trainset$diagnosis)

```

<a name="4.2"> </a>
<h3><b>Etapa 4.2 - Interpretando os resultados do o Modelo 3 (svm)</h3></b>

<b> Taxa de acerto do Modelo:</b>
```{r mean}
acuracia_modelo3
```

<h5>Comparamos apenas o primeiro e o segundo modelo ficaremos por enquanto com o primeiro modelo.</h5>

<a name="5"> </a>
<h3><b>Etapa 5 - Construindo o Modelo  4 - Random Forest</h3></b>

```{r modrandfo}
 # Criando o modelo
library(rpart)
modelo_rf_v1 = rpart(diagnosis ~ ., data = trainset, control = rpart.control(cp = .0005)) 

# Previsões nos dados de teste
tree_pred = predict(modelo_rf_v1, testset, type='class')

# Percentual de previsões corretas com dataset de teste
acuracia_modelo4 <- mean(tree_pred==testset$diagnosis) 
acuracia_modelo4

# Confusion Matrix
table(tree_pred, testset$diagnosis)
```
 
 

<a name="5.1"> </a>
<h3><b>Etapa 5.1 - Interpretando os resultados do o Modelo 4 (Random Forest)</h3></b>

<b> Taxa de acerto do Modelo:</b>

```{r mean1}
mean(tree_pred==testset$diagnosis) 
```



<h5>Comparamos apenas o primeiro e o segundo modelo ficaremos por enquanto com o primeiro modelo.</h5>

<a name="6"> </a>
<h3><b>Etapa 6 - Conclusão</h3></b>

<h5>* conforme podemos observar realizamos 04 modelos de Classificação de prevenção do tipo de câncer: 
* o KNN com uma acurácia de 98%;
* O segundo modelo tentamos otimizar o primeiro modelo, porém conseguimos um índice de acurácia menor, de 95%;
* O terceiro modelo, modamos para o Algoritmo SVM (Support Vector Machine) e conseguindo um aumento na acurácia, considerando como o modelo o melhor modelo, com uma acurácia de:
```{r acuracia}
acuracia_modelo3
```
* O Quarto e último modelo, bem conhecido, utilizamo o algoritmo Random Forest, porem com uma acurácia de:
```{r acuracia1}
acuracia_modelo4
```

* Apresentaremos como modelo final o modelo 03 - Support Vector Machine para entregar para a aprodução. </h5>

<p> <font color = white>...</font></p>

<h3><b>Dados Pessoais</h3></b>
<p class="shytext">Site <a href=https://www.rodolfoterra.com><strong> www.rodolfoterra.com</strong></a></p>

<p class="shytext">Linkedin <a href=https://www.linkedin.com/in/rodolffoterra/><strong>rodolffoterra</strong></a></p>

<p class="shytext">Repertório no GitHub: <a href=https://github.com/rodolffoterra/TestedeHipotese><strong>  Teste de Hipotese</strong></a></p>

<p class="shytext">E-mail <a href=consultoriaterra@hotmail.com><strong> consultoriaterra@hotmail.com</strong></a></p>

